{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"data/data_no_outlier/\"\n",
    "file_Xtrain = \"X_train_no_outlier.csv\"\n",
    "file_ytrain = \"y_train_no_outlier.csv\"\n",
    "file_Xtest  = \"X_test_no_outlier.csv\"\n",
    "file_ytest  = \"y_test_no_outlier.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(471866, 95) (232412, 95)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Harper/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "dfx0  = pd.read_csv(datapath+file_Xtrain)\n",
    "dfx0_ = pd.read_csv(datapath+file_Xtest)\n",
    "print(dfx0.shape, dfx0_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(704278, 95)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx0 = pd.concat([dfx0, dfx0_], axis=0, ignore_index=True)\n",
    "dfx0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(471866, 2) (232412, 2)\n"
     ]
    }
   ],
   "source": [
    "dfy0  = pd.read_csv(datapath+file_ytrain, names=[\"fullVisitorId\", \"transactionRevenue\"])\n",
    "dfy0_ = pd.read_csv(datapath+file_ytest,  names=[\"fullVisitorId\", \"transactionRevenue\"])\n",
    "print(dfy0.shape, dfy0_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(704278, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfy0 = pd.concat([dfy0, dfy0_], axis=0, ignore_index=True)\n",
    "dfy0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(704278, 97)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total = dfx0.copy()\n",
    "df_total[\"transactionRevenue\"] = dfy0[\"transactionRevenue\"]\n",
    "df_total[\"trans_label\"] = (df_total[\"transactionRevenue\"]>0)*1\n",
    "df_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullVisitorId</th>\n",
       "      <th>avg_hits</th>\n",
       "      <th>avg_pageviews</th>\n",
       "      <th>bounces</th>\n",
       "      <th>newVisits</th>\n",
       "      <th>fake_traffic</th>\n",
       "      <th>ctadwords</th>\n",
       "      <th>channelGrouping_Affiliates</th>\n",
       "      <th>channelGrouping_Direct</th>\n",
       "      <th>channelGrouping_Display</th>\n",
       "      <th>...</th>\n",
       "      <th>visit_hour_17</th>\n",
       "      <th>visit_hour_18</th>\n",
       "      <th>visit_hour_19</th>\n",
       "      <th>visit_hour_20</th>\n",
       "      <th>visit_hour_21</th>\n",
       "      <th>visit_hour_22</th>\n",
       "      <th>visit_hour_23</th>\n",
       "      <th>visitNumber</th>\n",
       "      <th>transactionRevenue</th>\n",
       "      <th>trans_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6144139465131417809</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>539966107187723079</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5943783354516112054</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>181201331571930526</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>818252312438640620</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fullVisitorId  avg_hits  avg_pageviews  bounces  newVisits  \\\n",
       "0  6144139465131417809       3.0            3.0      0.0        1.0   \n",
       "1   539966107187723079       2.0            2.0      0.0        0.0   \n",
       "2  5943783354516112054       1.0            1.0      1.0        1.0   \n",
       "3   181201331571930526       3.0            2.0      0.0        1.0   \n",
       "4   818252312438640620       1.0            1.0      1.0        1.0   \n",
       "\n",
       "   fake_traffic  ctadwords  channelGrouping_Affiliates  \\\n",
       "0             0          0                         0.0   \n",
       "1             0          0                         0.0   \n",
       "2             0          0                         0.0   \n",
       "3             0          0                         0.0   \n",
       "4             0          0                         0.0   \n",
       "\n",
       "   channelGrouping_Direct  channelGrouping_Display     ...       \\\n",
       "0                     1.0                      0.0     ...        \n",
       "1                     0.0                      0.0     ...        \n",
       "2                     0.0                      0.0     ...        \n",
       "3                     0.0                      0.0     ...        \n",
       "4                     0.0                      0.0     ...        \n",
       "\n",
       "   visit_hour_17  visit_hour_18  visit_hour_19  visit_hour_20  visit_hour_21  \\\n",
       "0            0.0            0.0            0.0            0.0            0.0   \n",
       "1            0.0            0.0            0.0            0.0            0.0   \n",
       "2            0.0            0.0            0.0            0.0            0.0   \n",
       "3            0.0            1.0            0.0            0.0            0.0   \n",
       "4            0.0            0.0            0.0            0.0            0.0   \n",
       "\n",
       "   visit_hour_22  visit_hour_23  visitNumber  transactionRevenue  trans_label  \n",
       "0            0.0            0.0            1                 0.0            0  \n",
       "1            0.0            0.0            1                 0.0            0  \n",
       "2            0.0            0.0            1                 0.0            0  \n",
       "3            0.0            0.0            1                 0.0            0  \n",
       "4            0.0            0.0            1                 0.0            0  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess for Imbalanced Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232412, 95) (232412, 2)\n"
     ]
    }
   ],
   "source": [
    "print(dfx0_.shape, dfy0_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Resample the Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(704278, 96)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df_total.drop(\"fullVisitorId\", axis=1)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(704278, 95) (704278, 1)\n"
     ]
    }
   ],
   "source": [
    "# Target variable is \"trans_label\"\n",
    "\n",
    "dfx1 = df1.drop(\"trans_label\", axis=1)\n",
    "dfy1 = pd.DataFrame({\"trans_label\" : df1[\"trans_label\"]})\n",
    "print(dfx1.shape, dfy1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    694333\n",
       "1      9945\n",
       "Name: trans_label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfy1[\"trans_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1388666, 95) (1388666, 1)\n"
     ]
    }
   ],
   "source": [
    "# Resample the dataset\n",
    "\n",
    "smote = SMOTE()\n",
    "dfx1_resampled, dfy1_resampled = smote.fit_resample(dfx1, dfy1)\n",
    "print(dfx1_resampled.shape, dfy1_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    694333\n",
       "0    694333\n",
       "Name: trans_label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfy1_resampled[\"trans_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Predictor Variables Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_feature(series):\n",
    "    '''\n",
    "    Use StandardScaler to standardizing a single feature\n",
    "    ----------\n",
    "    Parameters\n",
    "    series: A Series\n",
    "    ----------\n",
    "    Returns\n",
    "    scaled_array: A standardized numpy.array\n",
    "    '''\n",
    "    arr = np.reshape(series.tolist(), (-1,1))\n",
    "    stscaler = StandardScaler().fit(arr)\n",
    "    scaled_array = stscaler.transform(arr)\n",
    "    return scaled_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_dataframe(df):\n",
    "    '''\n",
    "    Use StandardScaler to standardizing a dataframe\n",
    "    ----------\n",
    "    Parameters\n",
    "    series: A dataframe\n",
    "    ----------\n",
    "    Returns\n",
    "    scaled_array: A standardized numpy.array\n",
    "    '''\n",
    "    stscaler = StandardScaler().fit(df)\n",
    "    scaled_array = stscaler.transform(df)\n",
    "    return scaled_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1388666, 95)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize the dataframe\n",
    "\n",
    "dfx2 = standardize_dataframe(dfx1_resampled)\n",
    "dfx2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1388666, 94)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete \"transactionRevenue\" from Predictor variables\n",
    "\n",
    "dfx2 = pd.DataFrame(dfx2, columns=dfx1_resampled.columns)\n",
    "dfx2 = dfx2.drop(\"transactionRevenue\", axis=1)\n",
    "dfx2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess for Imbalanced Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232412, 1)\n"
     ]
    }
   ],
   "source": [
    "dfy2_ = dfy0_.copy()\n",
    "dfy2_[\"trans_label\"] = (dfy2_[\"transactionRevenue\"]>0)*1\n",
    "dfy2_ = dfy2_.drop([\"fullVisitorId\", \"transactionRevenue\"], axis=1)\n",
    "print(dfy2_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232412, 94)\n"
     ]
    }
   ],
   "source": [
    "dfx2_ = standardize_dataframe(dfx0_)\n",
    "dfx2_ = pd.DataFrame(dfx2_, columns=dfx0_.columns)\n",
    "dfx2_ = dfx2_.drop(\"fullVisitorId\", axis=1)\n",
    "print(dfx2_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Train & Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1249799, 94) (1249799, 1) (138867, 94) (138867, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(dfx2, dfy1_resampled, test_size=0.1, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "624510"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[\"trans_label\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics  import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 features by their importance\n",
    "\n",
    "features_selected = ['avg_pageviews',\n",
    "                     'subContinent_Northern America',\n",
    "                     'avg_hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1249799, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select Features \n",
    "\n",
    "dfx4 = X_train[features_selected]\n",
    "dfx4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess for Balanced Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138867, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftx4 = X_test[features_selected]\n",
    "dftx4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess for Imbalanced Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232412, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx4_ = dfx2_[features_selected]\n",
    "dfx4_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Feature Extraction: PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1249799, 3)\n"
     ]
    }
   ],
   "source": [
    "# NOT using PCA\n",
    "X_train_pca = dfx4\n",
    "print(X_train_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess for Balanced Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(138867, 3)\n"
     ]
    }
   ],
   "source": [
    "X_test_pca = dftx4\n",
    "print(X_test_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess for Imbalanced Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232412, 3) (232412, 1)\n"
     ]
    }
   ],
   "source": [
    "X_ibtest = dfx4_[features_selected]\n",
    "y_ibtest = dfy2_\n",
    "print(X_ibtest.shape, y_ibtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Modeling: Classification for Transaction or Non-transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree         import DecisionTreeClassifier\n",
    "from sklearn.svm          import SVC\n",
    "from sklearn.ensemble     import RandomForestRegressor\n",
    "from sklearn.metrics      import mean_squared_error, r2_score\n",
    "from sklearn.metrics      import accuracy_score, classification_report\n",
    "#from sklearn.metrics      import accuracy_score, classification_report, f1_score, precision_score, recall_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Harper/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6.1) Run Logistic Regression\n",
    "\n",
    "s1_lr = LogisticRegression()\n",
    "s1_lr.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load the fitted model\n",
    "modelfile = 's1_lr.sav'\n",
    "pickle.dump(s1_lr, open(modelfile, 'wb'))\n",
    "#s1_lr = pickle.load(open(modelfile, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy   : 0.9530100440150776\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95    625289\n",
      "           1       0.94      0.96      0.95    624510\n",
      "\n",
      "    accuracy                           0.95   1249799\n",
      "   macro avg       0.95      0.95      0.95   1249799\n",
      "weighted avg       0.95      0.95      0.95   1249799\n",
      "\n",
      "==============================\n",
      "Test  Accuracy   : 0.9535238753627572\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95     69044\n",
      "           1       0.94      0.96      0.95     69823\n",
      "\n",
      "    accuracy                           0.95    138867\n",
      "   macro avg       0.95      0.95      0.95    138867\n",
      "weighted avg       0.95      0.95      0.95    138867\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "labels = [0, 1]\n",
    "\n",
    "y_pred_train = s1_lr.predict(X_train_pca)\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "classrpt = classification_report(y_train, y_pred_train, labels=labels)\n",
    "print(f\"Train Accuracy   : {accuracy}\")\n",
    "print(classrpt)\n",
    "print(\"==============================\")\n",
    "\n",
    "y_pred_test = s1_lr.predict(X_test_pca)\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "classrpt = classification_report(y_test, y_pred_test, labels=labels)\n",
    "print(f\"Test  Accuracy   : {accuracy}\")\n",
    "print(classrpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Accuracy   : 0.5617481025076158\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.56      0.71    229180\n",
      "           1       0.03      1.00      0.06      3232\n",
      "\n",
      "    accuracy                           0.56    232412\n",
      "   macro avg       0.52      0.78      0.39    232412\n",
      "weighted avg       0.99      0.56      0.71    232412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imbalanced Data Test\n",
    "\n",
    "y_pred_test = s1_lr.predict(X_ibtest)\n",
    "accuracy = accuracy_score(y_ibtest, y_pred_test)\n",
    "classrpt = classification_report(y_ibtest, y_pred_test, labels=labels)\n",
    "print(f\"Test  Accuracy   : {accuracy}\")\n",
    "print(classrpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105083"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
