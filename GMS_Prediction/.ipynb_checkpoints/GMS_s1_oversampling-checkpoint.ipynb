{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"data/data_no_outlier/\"\n",
    "file_Xtrain = \"X_train_no_outlier.csv\"\n",
    "file_ytrain = \"y_train_no_outlier.csv\"\n",
    "file_Xtest  = \"X_test_no_outlier.csv\"\n",
    "file_ytest  = \"y_test_no_outlier.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(471866, 95) (232412, 95)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Harper/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "dfx0  = pd.read_csv(datapath+file_Xtrain)\n",
    "dfx0_ = pd.read_csv(datapath+file_Xtest)\n",
    "print(dfx0.shape, dfx0_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfx0 = pd.concat([dfx0, dfx0_], axis=0, ignore_index=True)\n",
    "# dfx0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(471866, 2) (232412, 2)\n"
     ]
    }
   ],
   "source": [
    "dfy0  = pd.read_csv(datapath+file_ytrain, names=[\"fullVisitorId\", \"transactionRevenue\"])\n",
    "dfy0_ = pd.read_csv(datapath+file_ytest,  names=[\"fullVisitorId\", \"transactionRevenue\"])\n",
    "print(dfy0.shape, dfy0_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfy0 = pd.concat([dfy0, dfy0_], axis=0, ignore_index=True)\n",
    "# dfy0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(471866, 97)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total = dfx0.copy()\n",
    "df_total[\"transactionRevenue\"] = dfy0[\"transactionRevenue\"]\n",
    "df_total[\"trans_label\"] = (df_total[\"transactionRevenue\"]>0)*1\n",
    "df_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullVisitorId</th>\n",
       "      <th>avg_hits</th>\n",
       "      <th>avg_pageviews</th>\n",
       "      <th>bounces</th>\n",
       "      <th>newVisits</th>\n",
       "      <th>fake_traffic</th>\n",
       "      <th>ctadwords</th>\n",
       "      <th>channelGrouping_Affiliates</th>\n",
       "      <th>channelGrouping_Direct</th>\n",
       "      <th>channelGrouping_Display</th>\n",
       "      <th>...</th>\n",
       "      <th>visit_hour_17</th>\n",
       "      <th>visit_hour_18</th>\n",
       "      <th>visit_hour_19</th>\n",
       "      <th>visit_hour_20</th>\n",
       "      <th>visit_hour_21</th>\n",
       "      <th>visit_hour_22</th>\n",
       "      <th>visit_hour_23</th>\n",
       "      <th>visitNumber</th>\n",
       "      <th>transactionRevenue</th>\n",
       "      <th>trans_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6144139465131417809</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>539966107187723079</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5943783354516112054</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>181201331571930526</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>818252312438640620</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fullVisitorId  avg_hits  avg_pageviews  bounces  newVisits  \\\n",
       "0  6144139465131417809       3.0            3.0      0.0        1.0   \n",
       "1   539966107187723079       2.0            2.0      0.0        0.0   \n",
       "2  5943783354516112054       1.0            1.0      1.0        1.0   \n",
       "3   181201331571930526       3.0            2.0      0.0        1.0   \n",
       "4   818252312438640620       1.0            1.0      1.0        1.0   \n",
       "\n",
       "   fake_traffic  ctadwords  channelGrouping_Affiliates  \\\n",
       "0             0          0                         0.0   \n",
       "1             0          0                         0.0   \n",
       "2             0          0                         0.0   \n",
       "3             0          0                         0.0   \n",
       "4             0          0                         0.0   \n",
       "\n",
       "   channelGrouping_Direct  channelGrouping_Display     ...       \\\n",
       "0                     1.0                      0.0     ...        \n",
       "1                     0.0                      0.0     ...        \n",
       "2                     0.0                      0.0     ...        \n",
       "3                     0.0                      0.0     ...        \n",
       "4                     0.0                      0.0     ...        \n",
       "\n",
       "   visit_hour_17  visit_hour_18  visit_hour_19  visit_hour_20  visit_hour_21  \\\n",
       "0            0.0            0.0            0.0            0.0            0.0   \n",
       "1            0.0            0.0            0.0            0.0            0.0   \n",
       "2            0.0            0.0            0.0            0.0            0.0   \n",
       "3            0.0            1.0            0.0            0.0            0.0   \n",
       "4            0.0            0.0            0.0            0.0            0.0   \n",
       "\n",
       "   visit_hour_22  visit_hour_23  visitNumber  transactionRevenue  trans_label  \n",
       "0            0.0            0.0            1                 0.0            0  \n",
       "1            0.0            0.0            1                 0.0            0  \n",
       "2            0.0            0.0            1                 0.0            0  \n",
       "3            0.0            0.0            1                 0.0            0  \n",
       "4            0.0            0.0            1                 0.0            0  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess for Imbalanced Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232412, 95) (232412, 2)\n"
     ]
    }
   ],
   "source": [
    "print(dfx0_.shape, dfy0_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232412, 97)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx0_[\"transactionRevenue\"] = dfy0_[\"transactionRevenue\"]\n",
    "dfx0_[\"trans_label\"] = (dfx0_[\"transactionRevenue\"]>0)*1\n",
    "dfx0_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3)->1) Train & Test Split\n",
    "- Before Resampling and Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418637, 94) (418637, 1) (104660, 94) (104660, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_hold, X_test_hold, y_train_hold, y_test_hold = \\\n",
    "train_test_split(dfx2, dfy1_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train_hold.shape, y_train_hold.shape, X_test_hold.shape, y_test_hold.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73262, 94) (73262, 1) (31398, 94) (31398, 1)\n"
     ]
    }
   ],
   "source": [
    "# FOR-DEBUG: extra split\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(X_test_hold, y_test_hold, test_size=0.3, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8151"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[\"trans_label\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Resample the Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(471866, 96)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df_total.drop(\"fullVisitorId\", axis=1)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(471866, 95) (471866, 1)\n"
     ]
    }
   ],
   "source": [
    "# Target variable is \"trans_label\"\n",
    "\n",
    "dfx1 = df1.drop(\"trans_label\", axis=1)\n",
    "dfy1 = pd.DataFrame({\"trans_label\" : df1[\"trans_label\"]})\n",
    "print(dfx1.shape, dfy1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    465153\n",
       "1      6713\n",
       "Name: trans_label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfy1[\"trans_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(523297, 95) (523297, 1)\n"
     ]
    }
   ],
   "source": [
    "# Resample the dataset\n",
    "\n",
    "smote = SMOTE(sampling_strategy=0.125)\n",
    "dfx1_resampled, dfy1_resampled = smote.fit_resample(dfx1, dfy1)\n",
    "print(dfx1_resampled.shape, dfy1_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    465153\n",
       "1     58144\n",
       "Name: trans_label, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfy1_resampled[\"trans_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Predictor Variables Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_feature(series):\n",
    "    '''\n",
    "    Use StandardScaler to standardizing a single feature\n",
    "    ----------\n",
    "    Parameters\n",
    "    series: A Series\n",
    "    ----------\n",
    "    Returns\n",
    "    scaled_array: A standardized numpy.array\n",
    "    '''\n",
    "    arr = np.reshape(series.tolist(), (-1,1))\n",
    "    stscaler = StandardScaler().fit(arr)\n",
    "    scaled_array = stscaler.transform(arr)\n",
    "    return scaled_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_dataframe(df):\n",
    "    '''\n",
    "    Use StandardScaler to standardizing a dataframe\n",
    "    ----------\n",
    "    Parameters\n",
    "    series: A dataframe\n",
    "    ----------\n",
    "    Returns\n",
    "    scaled_array: A standardized numpy.array\n",
    "    '''\n",
    "    stscaler = StandardScaler().fit(df)\n",
    "    scaled_array = stscaler.transform(df)\n",
    "    return scaled_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(523297, 95)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize the dataframe\n",
    "\n",
    "dfx2 = standardize_dataframe(dfx1_resampled)\n",
    "dfx2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(523297, 94)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete \"transactionRevenue\" from Predictor variables\n",
    "\n",
    "dfx2 = pd.DataFrame(dfx2, columns=dfx1_resampled.columns)\n",
    "dfx2 = dfx2.drop(\"transactionRevenue\", axis=1)\n",
    "dfx2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess for Imbalanced Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232412, 1)\n"
     ]
    }
   ],
   "source": [
    "dfy2_ = dfy0_.copy()\n",
    "dfy2_[\"trans_label\"] = (dfy2_[\"transactionRevenue\"]>0)*1\n",
    "dfy2_ = dfy2_.drop([\"fullVisitorId\", \"transactionRevenue\"], axis=1)\n",
    "print(dfy2_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232412, 96)\n"
     ]
    }
   ],
   "source": [
    "dfx2_ = standardize_dataframe(dfx0_)\n",
    "dfx2_ = pd.DataFrame(dfx2_, columns=dfx0_.columns)\n",
    "dfx2_ = dfx2_.drop(\"fullVisitorId\", axis=1)\n",
    "print(dfx2_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics  import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run Random Forest to select features\n",
    "\n",
    "# rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "# rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model evaluation\n",
    "# labels = [0, 1]\n",
    "\n",
    "# y_pred_train_prob = rf.predict(X_train)\n",
    "# y_pred_train = (y_pred_train_prob >= 0.5)*1\n",
    "# accuracy = accuracy_score(y_train, y_pred_train)\n",
    "# classrpt = classification_report(y_train, y_pred_train, labels=labels)\n",
    "# print(f\"Train Accuracy   : {accuracy}\")\n",
    "# print(classrpt)\n",
    "# print(\"==============================\")\n",
    "\n",
    "# y_pred_test_prob = rf.predict(X_test)\n",
    "# y_pred_test = (y_pred_test_prob >= 0.5)*1\n",
    "# accuracy = accuracy_score(y_test, y_pred_test)\n",
    "# classrpt = classification_report(y_test, y_pred_test, labels=labels)\n",
    "# print(f\"Test  Accuracy   : {accuracy}\")\n",
    "# print(classrpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot feature importances\n",
    "\n",
    "# importances_rf = pd.Series(rf.feature_importances_, index = X_train.columns)\n",
    "# sorted_importances_rf = importances_rf.sort_values()\n",
    "# plt.figure(figsize=(10, 30))\n",
    "# sorted_importances_rf.plot(kind='barh', color='blue')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 5 first features by their importance\n",
    "\n",
    "# features_selected = sorted_importances_rf.index[-5:].tolist()\n",
    "# features_selected.reverse()\n",
    "# features_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73262, 4)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select Features \n",
    "features_selected= ['avg_pageviews',\n",
    "                    'subContinent_Northern America',\n",
    "                    'avg_hits',\n",
    "                    'channelGrouping_Organic Search']\n",
    "dfx4 = X_train[features_selected]\n",
    "dfx4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess for Balanced Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31398, 4)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftx4 = X_test[features_selected]\n",
    "dftx4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess for Imbalanced Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232412, 4)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx4_ = dfx2_[features_selected]\n",
    "dfx4_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Feature Extraction: PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit_pca(df, n_components):\n",
    "#     '''\n",
    "#     Uses sklearn.decomposition.PCA to fit a PCA model on \"df\".\n",
    "#     ----------\n",
    "#     Parameters\n",
    "#     df: A pandas.DataFrame\n",
    "#     n_components: An int. Number of principal components to keep\n",
    "#     ----------\n",
    "#     Returns\n",
    "#     An sklearn.decomposition.pca.PCA instance.\n",
    "#     '''\n",
    "#     pca = PCA(n_components=n_components)\n",
    "#     pca_fitted = pca.fit(df)\n",
    "#     return pca_fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_pca_variance(pca):\n",
    "#     '''\n",
    "#     Plots the variance explained by each of the principal components.\n",
    "#     Attributes are not scaled, hence a naive approach.\n",
    "#     ----------\n",
    "#     Parameters\n",
    "#     pca: An sklearn.decomposition.pca.PCA instance.\n",
    "#     ----------\n",
    "#     Returns\n",
    "#     A matplotlib.Axes instance.\n",
    "#     '''\n",
    "#     features = range(pca.n_components_)\n",
    "#     ax = plt.axes()\n",
    "#     plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "#     plt.plot(features, pca.explained_variance_ratio_)\n",
    "#     plt.xlabel('Dimension #')\n",
    "#     plt.ylabel('Explained Variance Ratio')\n",
    "#     plt.title(\"Fraction of Explained Variance\")\n",
    "#     plt.xticks(features)\n",
    "#     plt.show()\n",
    "#     return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pca_trans(pca, array):\n",
    "#     '''\n",
    "#     Applies the `pca` model on array.\n",
    "#     ----------\n",
    "#     Parameters\n",
    "#     pca: An sklearn.decomposition.PCA instance.\n",
    "#     ----------\n",
    "#     Returns\n",
    "#     A Numpy array\n",
    "#     '''\n",
    "#     reduced = pca.transform(array)\n",
    "#     return reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Try 5 PCA\n",
    "\n",
    "# pca_model = fit_pca(dfx4, 5)\n",
    "# plot_pca_variance(pca_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select 3 PCA to transform\n",
    "\n",
    "# pca_model = fit_pca(dfx4, 3)\n",
    "# X_train_pca = pca_trans(pca_model, dfx4)\n",
    "# print(X_train_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73262, 4)\n"
     ]
    }
   ],
   "source": [
    "# NOT using PCA\n",
    "X_train_pca = dfx4\n",
    "print(X_train_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess for Balanced Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_model = fit_pca(dftx4, 3)\n",
    "# X_test_pca = pca_trans(pca_model, dftx4)\n",
    "# print(X_test_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31398, 4)\n"
     ]
    }
   ],
   "source": [
    "X_test_pca = dftx4\n",
    "print(X_test_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess for Imbalanced Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232412, 4) (232412, 1)\n"
     ]
    }
   ],
   "source": [
    "# pca_model = fit_pca(dfx4_, 3)\n",
    "# X_ibtest = pca_trans(pca_model, dfx4_)\n",
    "\n",
    "X_ibtest = dfx4_\n",
    "y_ibtest = dfy2_\n",
    "print(X_ibtest.shape, y_ibtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Modeling: Classification for Transaction or Non-transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree         import DecisionTreeClassifier\n",
    "from sklearn.svm          import SVC\n",
    "from sklearn.ensemble     import RandomForestRegressor\n",
    "from sklearn.metrics      import mean_squared_error, r2_score\n",
    "from sklearn.metrics      import accuracy_score, classification_report\n",
    "#from sklearn.metrics      import accuracy_score, classification_report, f1_score, precision_score, recall_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Harper/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6.1) Run Logistic Regression\n",
    "\n",
    "s1_lr = LogisticRegression()\n",
    "s1_lr.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load the fitted model\n",
    "modelfile = 's1_lr.sav'\n",
    "pickle.dump(s1_lr, open(modelfile, 'wb'))\n",
    "#s1_lr = pickle.load(open(modelfile, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy   : 0.9506565477327946\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     65111\n",
      "           1       0.82      0.71      0.76      8151\n",
      "\n",
      "    accuracy                           0.95     73262\n",
      "   macro avg       0.89      0.85      0.87     73262\n",
      "weighted avg       0.95      0.95      0.95     73262\n",
      "\n",
      "==============================\n",
      "Test  Accuracy   : 0.9483088094783108\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     27785\n",
      "           1       0.81      0.72      0.76      3613\n",
      "\n",
      "    accuracy                           0.95     31398\n",
      "   macro avg       0.89      0.85      0.87     31398\n",
      "weighted avg       0.95      0.95      0.95     31398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "labels = [0, 1]\n",
    "\n",
    "y_pred_train = s1_lr.predict(X_train_pca)\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "classrpt = classification_report(y_train, y_pred_train, labels=labels)\n",
    "print(f\"Train Accuracy   : {accuracy}\")\n",
    "print(classrpt)\n",
    "print(\"==============================\")\n",
    "\n",
    "y_pred_test = s1_lr.predict(X_test_pca)\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "classrpt = classification_report(y_test, y_pred_test, labels=labels)\n",
    "print(f\"Test  Accuracy   : {accuracy}\")\n",
    "print(classrpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Accuracy   : 0.9388714868423317\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97    229180\n",
      "           1       0.18      0.96      0.30      3232\n",
      "\n",
      "    accuracy                           0.94    232412\n",
      "   macro avg       0.59      0.95      0.64    232412\n",
      "weighted avg       0.99      0.94      0.96    232412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imbalanced Data Test\n",
    "\n",
    "y_pred_test = s1_lr.predict(X_ibtest)\n",
    "accuracy = accuracy_score(y_ibtest, y_pred_test)\n",
    "classrpt = classification_report(y_ibtest, y_pred_test, labels=labels)\n",
    "print(f\"Test  Accuracy   : {accuracy}\")\n",
    "print(classrpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17205"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=42, splitter='best')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6.2) Run Decision Tree\n",
    "\n",
    "s1_dt = DecisionTreeClassifier(random_state=42)\n",
    "s1_dt.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load the fitted model\n",
    "modelfile = 's1_dt.sav'\n",
    "pickle.dump(s1_dt, open(modelfile, 'wb'))\n",
    "#s1_dt = pickle.load(open(modelfile, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy   : 0.9930659823646638\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     65111\n",
      "           1       0.99      0.95      0.97      8151\n",
      "\n",
      "    accuracy                           0.99     73262\n",
      "   macro avg       0.99      0.97      0.98     73262\n",
      "weighted avg       0.99      0.99      0.99     73262\n",
      "\n",
      "==============================\n",
      "Test  Accuracy   : 0.9702210331868272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98     27785\n",
      "           1       0.90      0.84      0.87      3613\n",
      "\n",
      "    accuracy                           0.97     31398\n",
      "   macro avg       0.94      0.91      0.92     31398\n",
      "weighted avg       0.97      0.97      0.97     31398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "labels = [0, 1]\n",
    "\n",
    "y_pred_train = s1_dt.predict(X_train_pca)\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "classrpt = classification_report(y_train, y_pred_train, labels=labels)\n",
    "print(f\"Train Accuracy   : {accuracy}\")\n",
    "print(classrpt)\n",
    "print(\"==============================\")\n",
    "\n",
    "y_pred_test = s1_dt.predict(X_test_pca)\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "classrpt = classification_report(y_test, y_pred_test, labels=labels)\n",
    "print(f\"Test  Accuracy   : {accuracy}\")\n",
    "print(classrpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Accuracy   : 0.6613643013269539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.66      0.79    229180\n",
      "           1       0.04      0.96      0.07      3232\n",
      "\n",
      "    accuracy                           0.66    232412\n",
      "   macro avg       0.52      0.81      0.43    232412\n",
      "weighted avg       0.99      0.66      0.78    232412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imbalanced Data Test\n",
    "\n",
    "y_pred_test = s1_dt.predict(X_ibtest)\n",
    "accuracy = accuracy_score(y_ibtest, y_pred_test)\n",
    "classrpt = classification_report(y_ibtest, y_pred_test, labels=labels)\n",
    "print(f\"Test  Accuracy   : {accuracy}\")\n",
    "print(classrpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Harper/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=1000, n_jobs=None, oob_score=False,\n",
       "                      random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6.3) Run Random Forest\n",
    "\n",
    "s1_rf = RandomForestRegressor(n_estimators=1000, random_state=42)\n",
    "s1_rf.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load the fitted model\n",
    "modelfile = 's1_rf.sav'\n",
    "pickle.dump(s1_rf, open(modelfile, 'wb'))\n",
    "#s1_rf = pickle.load(open(modelfile, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy   : 0.9930659823646638\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     65111\n",
      "           1       0.98      0.96      0.97      8151\n",
      "\n",
      "    accuracy                           0.99     73262\n",
      "   macro avg       0.99      0.98      0.98     73262\n",
      "weighted avg       0.99      0.99      0.99     73262\n",
      "\n",
      "==============================\n",
      "Test  Accuracy   : 0.9739473851837697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     27785\n",
      "           1       0.89      0.88      0.89      3613\n",
      "\n",
      "    accuracy                           0.97     31398\n",
      "   macro avg       0.94      0.93      0.94     31398\n",
      "weighted avg       0.97      0.97      0.97     31398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "labels = [0, 1]\n",
    "\n",
    "y_pred_train_prob = s1_rf.predict(X_train_pca)\n",
    "y_pred_train = (y_pred_train_prob >= 0.5)*1\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "classrpt = classification_report(y_train, y_pred_train, labels=labels)\n",
    "print(f\"Train Accuracy   : {accuracy}\")\n",
    "print(classrpt)\n",
    "print(\"==============================\")\n",
    "\n",
    "y_pred_test_prob = s1_rf.predict(X_test_pca)\n",
    "y_pred_test = (y_pred_test_prob >= 0.5)*1\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "classrpt = classification_report(y_test, y_pred_test, labels=labels)\n",
    "print(f\"Test  Accuracy   : {accuracy}\")\n",
    "print(classrpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Accuracy   : 0.858169974011669\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92    229180\n",
      "           1       0.09      0.97      0.16      3232\n",
      "\n",
      "    accuracy                           0.86    232412\n",
      "   macro avg       0.54      0.91      0.54    232412\n",
      "weighted avg       0.99      0.86      0.91    232412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imbalanced Data Test\n",
    "\n",
    "y_pred_test_prob = s1_rf.predict(X_ibtest)\n",
    "y_pred_test = (y_pred_test_prob >= 0.5)*1\n",
    "accuracy = accuracy_score(y_ibtest, y_pred_test)\n",
    "classrpt = classification_report(y_ibtest, y_pred_test, labels=labels)\n",
    "print(f\"Test  Accuracy   : {accuracy}\")\n",
    "print(classrpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36017"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Harper/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sklearn.svm._classes.SVC"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6.4) Run SVM\n",
    "\n",
    "s1_svc = SVC(kernel='rbf', gamma=0.25).fit(X_train_pca, y_train)\n",
    "type(s1_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load the fitted model\n",
    "modelfile = 's1_svc.sav'\n",
    "pickle.dump(s1_svc, open(modelfile, 'wb'))\n",
    "#s1_svc = pickle.load(open(modelfile, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy   : 0.9628047282356474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98     65111\n",
      "           1       0.80      0.88      0.84      8151\n",
      "\n",
      "    accuracy                           0.96     73262\n",
      "   macro avg       0.89      0.93      0.91     73262\n",
      "weighted avg       0.96      0.96      0.96     73262\n",
      "\n",
      "==============================\n",
      "Test  Accuracy   : 0.9628001783553093\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     27785\n",
      "           1       0.81      0.89      0.85      3613\n",
      "\n",
      "    accuracy                           0.96     31398\n",
      "   macro avg       0.90      0.93      0.91     31398\n",
      "weighted avg       0.96      0.96      0.96     31398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "labels = [0, 1]\n",
    "\n",
    "y_pred_train = s1_svc.predict(X_train_pca)\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "classrpt = classification_report(y_train, y_pred_train, labels=labels)\n",
    "print(f\"Train Accuracy   : {accuracy}\")\n",
    "print(classrpt)\n",
    "print(\"==============================\")\n",
    "\n",
    "y_pred_test = s1_svc.predict(X_test_pca)\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "classrpt = classification_report(y_test, y_pred_test, labels=labels)\n",
    "print(f\"Test  Accuracy   : {accuracy}\")\n",
    "print(classrpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Accuracy   : 0.9269831161902139\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96    229180\n",
      "           1       0.16      0.97      0.27      3232\n",
      "\n",
      "    accuracy                           0.93    232412\n",
      "   macro avg       0.58      0.95      0.62    232412\n",
      "weighted avg       0.99      0.93      0.95    232412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imbalanced Data Test\n",
    "\n",
    "y_pred_test = s1_svc.predict(X_ibtest)\n",
    "accuracy = accuracy_score(y_ibtest, y_pred_test)\n",
    "classrpt = classification_report(y_ibtest, y_pred_test, labels=labels)\n",
    "print(f\"Test  Accuracy   : {accuracy}\")\n",
    "print(classrpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20032"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
